{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pertemuan 11 - Perceptron\n",
        "\n",
        "NIM     : 2041720140 <br>\n",
        "Nama    : Ananda Ayu Sekar Wiranti <br>\n",
        "Kelas   : TI-3A <br>"
      ],
      "metadata": {
        "id": "YoPtrwvMKqS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Chb7mmLx2sp2"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pembacaan data dan visualisasi\n",
        "\n",
        "df = pd.read_csv('iris.csv', header=None)\n",
        "data = {\n",
        "    'Iris-setosa' : 1,\n",
        "    'Iris-versicolor' : 2,\n",
        "    'Iris-virginica' : 3\n",
        "}\n",
        "\n",
        "df[4] = df[4].map(data)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0FDvx20A2wPu",
        "outputId": "e2e7fe85-ba55-42d2-cf58-2bdc10a1e2bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0    1    2    3  4\n",
              "0  5.1  3.5  1.4  0.2  1\n",
              "1  4.9  3.0  1.4  0.2  1\n",
              "2  4.7  3.2  1.3  0.2  1\n",
              "3  4.6  3.1  1.5  0.2  1\n",
              "4  5.0  3.6  1.4  0.2  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01687387-2bb6-423d-ae7b-07ad2cd8f702\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01687387-2bb6-423d-ae7b-07ad2cd8f702')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01687387-2bb6-423d-ae7b-07ad2cd8f702 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01687387-2bb6-423d-ae7b-07ad2cd8f702');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:1]\n",
        "y = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "8yIHElrF3VYV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
      ],
      "metadata": {
        "id": "dl6BH65T36rs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron menggunakan keras"
      ],
      "metadata": {
        "id": "WjsVksYYK_IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat 'Perceptron' menggunakan Keras API\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=18, activation='relu', input_dim=len(X_train.columns)))\n",
        "model.add(Dense(units=52, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jnzBWNL16E5C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perceptron menggunakan penurunan gradien stokastik dengan pembagian validasi 20%\n",
        "model.fit(X_train, y_train, epochs=225, batch_size=25, verbose=1, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IzcmtI_ItnI",
        "outputId": "8d887b00-6d6e-46e8-e22e-1d18f6332a0a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/225\n",
            "4/4 [==============================] - 1s 61ms/step - loss: 0.8272 - accuracy: 0.0312 - val_loss: 0.4118 - val_accuracy: 0.3333\n",
            "Epoch 2/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1960 - accuracy: 0.3438 - val_loss: -0.2230 - val_accuracy: 0.3333\n",
            "Epoch 3/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -0.3977 - accuracy: 0.3438 - val_loss: -0.7900 - val_accuracy: 0.3333\n",
            "Epoch 4/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -0.9362 - accuracy: 0.3438 - val_loss: -1.3254 - val_accuracy: 0.3333\n",
            "Epoch 5/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1.4495 - accuracy: 0.3438 - val_loss: -1.8359 - val_accuracy: 0.3333\n",
            "Epoch 6/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1.9473 - accuracy: 0.3438 - val_loss: -2.3202 - val_accuracy: 0.3333\n",
            "Epoch 7/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -2.3738 - accuracy: 0.3438 - val_loss: -2.7863 - val_accuracy: 0.3333\n",
            "Epoch 8/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -2.8219 - accuracy: 0.3438 - val_loss: -3.2566 - val_accuracy: 0.3333\n",
            "Epoch 9/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3.2991 - accuracy: 0.3438 - val_loss: -3.7308 - val_accuracy: 0.3333\n",
            "Epoch 10/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3.7398 - accuracy: 0.3438 - val_loss: -4.2153 - val_accuracy: 0.3333\n",
            "Epoch 11/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -4.2086 - accuracy: 0.3438 - val_loss: -4.7195 - val_accuracy: 0.3333\n",
            "Epoch 12/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4.7277 - accuracy: 0.3438 - val_loss: -5.2439 - val_accuracy: 0.3333\n",
            "Epoch 13/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -5.2155 - accuracy: 0.3438 - val_loss: -5.7998 - val_accuracy: 0.3333\n",
            "Epoch 14/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -5.7619 - accuracy: 0.3438 - val_loss: -6.3745 - val_accuracy: 0.3333\n",
            "Epoch 15/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -6.3249 - accuracy: 0.3438 - val_loss: -6.9746 - val_accuracy: 0.3333\n",
            "Epoch 16/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -6.8938 - accuracy: 0.3438 - val_loss: -7.6231 - val_accuracy: 0.3333\n",
            "Epoch 17/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -7.5649 - accuracy: 0.3438 - val_loss: -8.3051 - val_accuracy: 0.3333\n",
            "Epoch 18/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -8.2057 - accuracy: 0.3438 - val_loss: -9.0464 - val_accuracy: 0.3333\n",
            "Epoch 19/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -8.9345 - accuracy: 0.3438 - val_loss: -9.8345 - val_accuracy: 0.3333\n",
            "Epoch 20/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -9.7234 - accuracy: 0.3438 - val_loss: -10.6731 - val_accuracy: 0.3333\n",
            "Epoch 21/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -10.5618 - accuracy: 0.3438 - val_loss: -11.5678 - val_accuracy: 0.3333\n",
            "Epoch 22/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -11.3968 - accuracy: 0.3438 - val_loss: -12.5219 - val_accuracy: 0.3333\n",
            "Epoch 23/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -12.3774 - accuracy: 0.3438 - val_loss: -13.5213 - val_accuracy: 0.3333\n",
            "Epoch 24/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -13.3666 - accuracy: 0.3438 - val_loss: -14.5926 - val_accuracy: 0.3333\n",
            "Epoch 25/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -14.3895 - accuracy: 0.3438 - val_loss: -15.7497 - val_accuracy: 0.3333\n",
            "Epoch 26/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -15.4827 - accuracy: 0.3438 - val_loss: -16.9876 - val_accuracy: 0.3333\n",
            "Epoch 27/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -16.7194 - accuracy: 0.3438 - val_loss: -18.2875 - val_accuracy: 0.3333\n",
            "Epoch 28/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -18.0662 - accuracy: 0.3438 - val_loss: -19.6447 - val_accuracy: 0.3333\n",
            "Epoch 29/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -19.3072 - accuracy: 0.3438 - val_loss: -21.1221 - val_accuracy: 0.3333\n",
            "Epoch 30/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -20.7549 - accuracy: 0.3438 - val_loss: -22.6590 - val_accuracy: 0.3333\n",
            "Epoch 31/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -22.2717 - accuracy: 0.3438 - val_loss: -24.2834 - val_accuracy: 0.3333\n",
            "Epoch 32/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -23.9207 - accuracy: 0.3438 - val_loss: -25.9878 - val_accuracy: 0.3333\n",
            "Epoch 33/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -25.5533 - accuracy: 0.3438 - val_loss: -27.8133 - val_accuracy: 0.3333\n",
            "Epoch 34/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -27.2678 - accuracy: 0.3438 - val_loss: -29.7540 - val_accuracy: 0.3333\n",
            "Epoch 35/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -29.2254 - accuracy: 0.3438 - val_loss: -31.7604 - val_accuracy: 0.3333\n",
            "Epoch 36/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -31.2356 - accuracy: 0.3438 - val_loss: -33.8686 - val_accuracy: 0.3333\n",
            "Epoch 37/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -33.2886 - accuracy: 0.3438 - val_loss: -36.1060 - val_accuracy: 0.3333\n",
            "Epoch 38/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -35.4520 - accuracy: 0.3438 - val_loss: -38.4679 - val_accuracy: 0.3333\n",
            "Epoch 39/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -37.7056 - accuracy: 0.3438 - val_loss: -40.9640 - val_accuracy: 0.3333\n",
            "Epoch 40/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -40.2188 - accuracy: 0.3438 - val_loss: -43.5523 - val_accuracy: 0.3333\n",
            "Epoch 41/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -42.7972 - accuracy: 0.3438 - val_loss: -46.2640 - val_accuracy: 0.3333\n",
            "Epoch 42/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -45.3309 - accuracy: 0.3438 - val_loss: -49.1559 - val_accuracy: 0.3333\n",
            "Epoch 43/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -48.2362 - accuracy: 0.3438 - val_loss: -52.1440 - val_accuracy: 0.3333\n",
            "Epoch 44/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -51.0922 - accuracy: 0.3438 - val_loss: -55.2938 - val_accuracy: 0.3333\n",
            "Epoch 45/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -54.0915 - accuracy: 0.3438 - val_loss: -58.5938 - val_accuracy: 0.3333\n",
            "Epoch 46/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -57.4095 - accuracy: 0.3438 - val_loss: -61.9869 - val_accuracy: 0.3333\n",
            "Epoch 47/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -60.6322 - accuracy: 0.3438 - val_loss: -65.5652 - val_accuracy: 0.3333\n",
            "Epoch 48/225\n",
            "4/4 [==============================] - 0s 13ms/step - loss: -64.1573 - accuracy: 0.3438 - val_loss: -69.2602 - val_accuracy: 0.3333\n",
            "Epoch 49/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -67.7636 - accuracy: 0.3438 - val_loss: -73.1110 - val_accuracy: 0.3333\n",
            "Epoch 50/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -71.5255 - accuracy: 0.3438 - val_loss: -77.1309 - val_accuracy: 0.3333\n",
            "Epoch 51/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -75.5456 - accuracy: 0.3438 - val_loss: -81.2850 - val_accuracy: 0.3333\n",
            "Epoch 52/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -79.4946 - accuracy: 0.3438 - val_loss: -85.6662 - val_accuracy: 0.3333\n",
            "Epoch 53/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -83.6630 - accuracy: 0.3438 - val_loss: -90.2357 - val_accuracy: 0.3333\n",
            "Epoch 54/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -88.1742 - accuracy: 0.3438 - val_loss: -94.9388 - val_accuracy: 0.3333\n",
            "Epoch 55/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -92.5454 - accuracy: 0.3438 - val_loss: -99.8704 - val_accuracy: 0.3333\n",
            "Epoch 56/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -97.4641 - accuracy: 0.3438 - val_loss: -104.9009 - val_accuracy: 0.3333\n",
            "Epoch 57/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -102.5342 - accuracy: 0.3438 - val_loss: -110.0617 - val_accuracy: 0.3333\n",
            "Epoch 58/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -107.4176 - accuracy: 0.3438 - val_loss: -115.5076 - val_accuracy: 0.3333\n",
            "Epoch 59/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -112.8181 - accuracy: 0.3438 - val_loss: -121.1127 - val_accuracy: 0.3333\n",
            "Epoch 60/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -118.1729 - accuracy: 0.3438 - val_loss: -126.9614 - val_accuracy: 0.3333\n",
            "Epoch 61/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -123.6577 - accuracy: 0.3438 - val_loss: -133.0457 - val_accuracy: 0.3333\n",
            "Epoch 62/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -129.7189 - accuracy: 0.3438 - val_loss: -139.2380 - val_accuracy: 0.3333\n",
            "Epoch 63/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -135.7063 - accuracy: 0.3438 - val_loss: -145.6710 - val_accuracy: 0.3333\n",
            "Epoch 64/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -142.0103 - accuracy: 0.3438 - val_loss: -152.3033 - val_accuracy: 0.3333\n",
            "Epoch 65/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -148.3861 - accuracy: 0.3438 - val_loss: -159.2111 - val_accuracy: 0.3333\n",
            "Epoch 66/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -155.3732 - accuracy: 0.3438 - val_loss: -166.2566 - val_accuracy: 0.3333\n",
            "Epoch 67/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -162.2251 - accuracy: 0.3438 - val_loss: -173.5864 - val_accuracy: 0.3333\n",
            "Epoch 68/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -168.9780 - accuracy: 0.3438 - val_loss: -181.3153 - val_accuracy: 0.3333\n",
            "Epoch 69/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -176.5101 - accuracy: 0.3438 - val_loss: -189.1945 - val_accuracy: 0.3333\n",
            "Epoch 70/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -184.1246 - accuracy: 0.3438 - val_loss: -197.2904 - val_accuracy: 0.3333\n",
            "Epoch 71/225\n",
            "4/4 [==============================] - 0s 14ms/step - loss: -192.3505 - accuracy: 0.3438 - val_loss: -205.5184 - val_accuracy: 0.3333\n",
            "Epoch 72/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -200.3232 - accuracy: 0.3438 - val_loss: -214.0667 - val_accuracy: 0.3333\n",
            "Epoch 73/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -208.3021 - accuracy: 0.3438 - val_loss: -223.0076 - val_accuracy: 0.3333\n",
            "Epoch 74/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -217.0475 - accuracy: 0.3438 - val_loss: -232.1439 - val_accuracy: 0.3333\n",
            "Epoch 75/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -225.8855 - accuracy: 0.3438 - val_loss: -241.5437 - val_accuracy: 0.3333\n",
            "Epoch 76/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -234.8360 - accuracy: 0.3438 - val_loss: -251.2476 - val_accuracy: 0.3333\n",
            "Epoch 77/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -244.3034 - accuracy: 0.3438 - val_loss: -261.1451 - val_accuracy: 0.3333\n",
            "Epoch 78/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -254.0927 - accuracy: 0.3438 - val_loss: -271.2752 - val_accuracy: 0.3333\n",
            "Epoch 79/225\n",
            "4/4 [==============================] - 0s 13ms/step - loss: -264.0376 - accuracy: 0.3438 - val_loss: -281.6698 - val_accuracy: 0.3333\n",
            "Epoch 80/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -273.8558 - accuracy: 0.3438 - val_loss: -292.4641 - val_accuracy: 0.3333\n",
            "Epoch 81/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -284.3708 - accuracy: 0.3438 - val_loss: -303.4961 - val_accuracy: 0.3333\n",
            "Epoch 82/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -294.5641 - accuracy: 0.3438 - val_loss: -314.9725 - val_accuracy: 0.3333\n",
            "Epoch 83/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -306.3955 - accuracy: 0.3438 - val_loss: -326.4071 - val_accuracy: 0.3333\n",
            "Epoch 84/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -316.6365 - accuracy: 0.3438 - val_loss: -338.4763 - val_accuracy: 0.3333\n",
            "Epoch 85/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -328.6339 - accuracy: 0.3438 - val_loss: -350.6267 - val_accuracy: 0.3333\n",
            "Epoch 86/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -340.7573 - accuracy: 0.3438 - val_loss: -362.9402 - val_accuracy: 0.3333\n",
            "Epoch 87/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -352.8593 - accuracy: 0.3438 - val_loss: -375.5758 - val_accuracy: 0.3333\n",
            "Epoch 88/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -364.8511 - accuracy: 0.3438 - val_loss: -388.6965 - val_accuracy: 0.3333\n",
            "Epoch 89/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -377.3432 - accuracy: 0.3438 - val_loss: -402.1621 - val_accuracy: 0.3333\n",
            "Epoch 90/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -390.2769 - accuracy: 0.3438 - val_loss: -415.9206 - val_accuracy: 0.3333\n",
            "Epoch 91/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -403.4599 - accuracy: 0.3438 - val_loss: -430.0089 - val_accuracy: 0.3333\n",
            "Epoch 92/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -417.7950 - accuracy: 0.3438 - val_loss: -444.1306 - val_accuracy: 0.3333\n",
            "Epoch 93/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -431.2978 - accuracy: 0.3438 - val_loss: -458.7566 - val_accuracy: 0.3333\n",
            "Epoch 94/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -445.2301 - accuracy: 0.3438 - val_loss: -473.8234 - val_accuracy: 0.3333\n",
            "Epoch 95/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -459.2452 - accuracy: 0.3438 - val_loss: -489.3581 - val_accuracy: 0.3333\n",
            "Epoch 96/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -474.4127 - accuracy: 0.3438 - val_loss: -505.0491 - val_accuracy: 0.3333\n",
            "Epoch 97/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -489.4624 - accuracy: 0.3438 - val_loss: -521.0720 - val_accuracy: 0.3333\n",
            "Epoch 98/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -505.5549 - accuracy: 0.3438 - val_loss: -537.1545 - val_accuracy: 0.3333\n",
            "Epoch 99/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -520.3987 - accuracy: 0.3438 - val_loss: -553.9002 - val_accuracy: 0.3333\n",
            "Epoch 100/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -537.5010 - accuracy: 0.3438 - val_loss: -570.6207 - val_accuracy: 0.3333\n",
            "Epoch 101/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -552.9459 - accuracy: 0.3438 - val_loss: -588.0663 - val_accuracy: 0.3333\n",
            "Epoch 102/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -569.7894 - accuracy: 0.3438 - val_loss: -605.7928 - val_accuracy: 0.3333\n",
            "Epoch 103/225\n",
            "4/4 [==============================] - 0s 17ms/step - loss: -587.5438 - accuracy: 0.3438 - val_loss: -623.6329 - val_accuracy: 0.3333\n",
            "Epoch 104/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -604.7471 - accuracy: 0.3438 - val_loss: -641.9452 - val_accuracy: 0.3333\n",
            "Epoch 105/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -621.9736 - accuracy: 0.3438 - val_loss: -660.8311 - val_accuracy: 0.3333\n",
            "Epoch 106/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -639.8124 - accuracy: 0.3438 - val_loss: -680.1513 - val_accuracy: 0.3333\n",
            "Epoch 107/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -658.1736 - accuracy: 0.3438 - val_loss: -699.7817 - val_accuracy: 0.3333\n",
            "Epoch 108/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -677.5615 - accuracy: 0.3438 - val_loss: -719.5078 - val_accuracy: 0.3333\n",
            "Epoch 109/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -696.9038 - accuracy: 0.3438 - val_loss: -739.5329 - val_accuracy: 0.3333\n",
            "Epoch 110/225\n",
            "4/4 [==============================] - 0s 12ms/step - loss: -715.9399 - accuracy: 0.3438 - val_loss: -760.1174 - val_accuracy: 0.3333\n",
            "Epoch 111/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -735.6160 - accuracy: 0.3438 - val_loss: -781.1202 - val_accuracy: 0.3333\n",
            "Epoch 112/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -756.6359 - accuracy: 0.3438 - val_loss: -802.2145 - val_accuracy: 0.3333\n",
            "Epoch 113/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -776.6831 - accuracy: 0.3438 - val_loss: -823.9443 - val_accuracy: 0.3333\n",
            "Epoch 114/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -797.4836 - accuracy: 0.3438 - val_loss: -846.1390 - val_accuracy: 0.3333\n",
            "Epoch 115/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -819.1557 - accuracy: 0.3438 - val_loss: -868.5581 - val_accuracy: 0.3333\n",
            "Epoch 116/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -840.5813 - accuracy: 0.3438 - val_loss: -891.4717 - val_accuracy: 0.3333\n",
            "Epoch 117/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -863.5193 - accuracy: 0.3438 - val_loss: -914.4948 - val_accuracy: 0.3333\n",
            "Epoch 118/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -886.0828 - accuracy: 0.3438 - val_loss: -937.9582 - val_accuracy: 0.3333\n",
            "Epoch 119/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -908.4836 - accuracy: 0.3438 - val_loss: -962.0441 - val_accuracy: 0.3333\n",
            "Epoch 120/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -931.8127 - accuracy: 0.3438 - val_loss: -986.5322 - val_accuracy: 0.3333\n",
            "Epoch 121/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -955.1340 - accuracy: 0.3438 - val_loss: -1011.5867 - val_accuracy: 0.3333\n",
            "Epoch 122/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -979.6673 - accuracy: 0.3438 - val_loss: -1036.9388 - val_accuracy: 0.3333\n",
            "Epoch 123/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1002.6724 - accuracy: 0.3438 - val_loss: -1063.2218 - val_accuracy: 0.3333\n",
            "Epoch 124/225\n",
            "4/4 [==============================] - 0s 13ms/step - loss: -1028.3917 - accuracy: 0.3438 - val_loss: -1089.4824 - val_accuracy: 0.3333\n",
            "Epoch 125/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1053.0815 - accuracy: 0.3438 - val_loss: -1116.2748 - val_accuracy: 0.3333\n",
            "Epoch 126/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1078.6669 - accuracy: 0.3438 - val_loss: -1143.3900 - val_accuracy: 0.3333\n",
            "Epoch 127/225\n",
            "4/4 [==============================] - 0s 12ms/step - loss: -1105.4385 - accuracy: 0.3438 - val_loss: -1170.5834 - val_accuracy: 0.3333\n",
            "Epoch 128/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -1131.8851 - accuracy: 0.3438 - val_loss: -1198.1830 - val_accuracy: 0.3333\n",
            "Epoch 129/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -1158.2821 - accuracy: 0.3438 - val_loss: -1226.3588 - val_accuracy: 0.3333\n",
            "Epoch 130/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1185.6073 - accuracy: 0.3438 - val_loss: -1254.8339 - val_accuracy: 0.3333\n",
            "Epoch 131/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -1214.3529 - accuracy: 0.3438 - val_loss: -1283.3400 - val_accuracy: 0.3333\n",
            "Epoch 132/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1239.8989 - accuracy: 0.3438 - val_loss: -1313.2257 - val_accuracy: 0.3333\n",
            "Epoch 133/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1269.1968 - accuracy: 0.3438 - val_loss: -1343.1389 - val_accuracy: 0.3333\n",
            "Epoch 134/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1297.2728 - accuracy: 0.3438 - val_loss: -1373.6849 - val_accuracy: 0.3333\n",
            "Epoch 135/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1327.4126 - accuracy: 0.3438 - val_loss: -1404.2777 - val_accuracy: 0.3333\n",
            "Epoch 136/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1357.8569 - accuracy: 0.3438 - val_loss: -1434.9918 - val_accuracy: 0.3333\n",
            "Epoch 137/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -1386.9525 - accuracy: 0.3438 - val_loss: -1466.5509 - val_accuracy: 0.3333\n",
            "Epoch 138/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -1418.5400 - accuracy: 0.3438 - val_loss: -1498.2246 - val_accuracy: 0.3333\n",
            "Epoch 139/225\n",
            "4/4 [==============================] - 0s 17ms/step - loss: -1447.3881 - accuracy: 0.3438 - val_loss: -1531.2218 - val_accuracy: 0.3333\n",
            "Epoch 140/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1479.7941 - accuracy: 0.3438 - val_loss: -1564.2565 - val_accuracy: 0.3333\n",
            "Epoch 141/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -1510.9486 - accuracy: 0.3438 - val_loss: -1598.0020 - val_accuracy: 0.3333\n",
            "Epoch 142/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1545.1929 - accuracy: 0.3438 - val_loss: -1631.4515 - val_accuracy: 0.3333\n",
            "Epoch 143/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1575.1024 - accuracy: 0.3438 - val_loss: -1666.4904 - val_accuracy: 0.3333\n",
            "Epoch 144/225\n",
            "4/4 [==============================] - 0s 15ms/step - loss: -1609.6063 - accuracy: 0.3438 - val_loss: -1701.3721 - val_accuracy: 0.3333\n",
            "Epoch 145/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1643.7725 - accuracy: 0.3438 - val_loss: -1736.4515 - val_accuracy: 0.3333\n",
            "Epoch 146/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1677.9819 - accuracy: 0.3438 - val_loss: -1772.0387 - val_accuracy: 0.3333\n",
            "Epoch 147/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1712.5704 - accuracy: 0.3438 - val_loss: -1808.2050 - val_accuracy: 0.3333\n",
            "Epoch 148/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1747.2743 - accuracy: 0.3438 - val_loss: -1845.0244 - val_accuracy: 0.3333\n",
            "Epoch 149/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1782.8571 - accuracy: 0.3438 - val_loss: -1882.3257 - val_accuracy: 0.3333\n",
            "Epoch 150/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -1818.0039 - accuracy: 0.3438 - val_loss: -1920.4189 - val_accuracy: 0.3333\n",
            "Epoch 151/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1853.4452 - accuracy: 0.3438 - val_loss: -1959.3076 - val_accuracy: 0.3333\n",
            "Epoch 152/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1891.4926 - accuracy: 0.3438 - val_loss: -1998.1313 - val_accuracy: 0.3333\n",
            "Epoch 153/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -1930.4736 - accuracy: 0.3438 - val_loss: -2036.8286 - val_accuracy: 0.3333\n",
            "Epoch 154/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -1967.0363 - accuracy: 0.3438 - val_loss: -2076.5774 - val_accuracy: 0.3333\n",
            "Epoch 155/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2003.9825 - accuracy: 0.3438 - val_loss: -2117.2876 - val_accuracy: 0.3333\n",
            "Epoch 156/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2043.7882 - accuracy: 0.3438 - val_loss: -2157.9976 - val_accuracy: 0.3333\n",
            "Epoch 157/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2085.4758 - accuracy: 0.3438 - val_loss: -2198.2295 - val_accuracy: 0.3333\n",
            "Epoch 158/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -2121.5127 - accuracy: 0.3438 - val_loss: -2240.5383 - val_accuracy: 0.3333\n",
            "Epoch 159/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2164.9116 - accuracy: 0.3438 - val_loss: -2282.1550 - val_accuracy: 0.3333\n",
            "Epoch 160/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2202.5752 - accuracy: 0.3438 - val_loss: -2325.5562 - val_accuracy: 0.3333\n",
            "Epoch 161/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -2245.9893 - accuracy: 0.3438 - val_loss: -2368.6648 - val_accuracy: 0.3333\n",
            "Epoch 162/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2287.5408 - accuracy: 0.3438 - val_loss: -2412.4326 - val_accuracy: 0.3333\n",
            "Epoch 163/225\n",
            "4/4 [==============================] - 0s 15ms/step - loss: -2328.2788 - accuracy: 0.3438 - val_loss: -2457.2737 - val_accuracy: 0.3333\n",
            "Epoch 164/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2371.6064 - accuracy: 0.3438 - val_loss: -2502.2249 - val_accuracy: 0.3333\n",
            "Epoch 165/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2414.0359 - accuracy: 0.3438 - val_loss: -2547.8098 - val_accuracy: 0.3333\n",
            "Epoch 166/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2458.4758 - accuracy: 0.3438 - val_loss: -2593.3940 - val_accuracy: 0.3333\n",
            "Epoch 167/225\n",
            "4/4 [==============================] - 0s 16ms/step - loss: -2502.8091 - accuracy: 0.3438 - val_loss: -2639.3455 - val_accuracy: 0.3333\n",
            "Epoch 168/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -2547.2004 - accuracy: 0.3438 - val_loss: -2685.9417 - val_accuracy: 0.3333\n",
            "Epoch 169/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2591.0139 - accuracy: 0.3438 - val_loss: -2733.5916 - val_accuracy: 0.3333\n",
            "Epoch 170/225\n",
            "4/4 [==============================] - 0s 12ms/step - loss: -2639.0830 - accuracy: 0.3438 - val_loss: -2780.7578 - val_accuracy: 0.3333\n",
            "Epoch 171/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2683.0254 - accuracy: 0.3438 - val_loss: -2829.3665 - val_accuracy: 0.3333\n",
            "Epoch 172/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2728.4250 - accuracy: 0.3438 - val_loss: -2878.7971 - val_accuracy: 0.3333\n",
            "Epoch 173/225\n",
            "4/4 [==============================] - 0s 12ms/step - loss: -2777.8672 - accuracy: 0.3438 - val_loss: -2927.6436 - val_accuracy: 0.3333\n",
            "Epoch 174/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -2825.5300 - accuracy: 0.3438 - val_loss: -2977.0605 - val_accuracy: 0.3333\n",
            "Epoch 175/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2872.5237 - accuracy: 0.3438 - val_loss: -3027.6414 - val_accuracy: 0.3333\n",
            "Epoch 176/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2920.5886 - accuracy: 0.3438 - val_loss: -3078.9990 - val_accuracy: 0.3333\n",
            "Epoch 177/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -2970.9807 - accuracy: 0.3438 - val_loss: -3130.4121 - val_accuracy: 0.3333\n",
            "Epoch 178/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3020.3945 - accuracy: 0.3438 - val_loss: -3182.5693 - val_accuracy: 0.3333\n",
            "Epoch 179/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3070.0549 - accuracy: 0.3438 - val_loss: -3235.5281 - val_accuracy: 0.3333\n",
            "Epoch 180/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3120.7041 - accuracy: 0.3438 - val_loss: -3289.0461 - val_accuracy: 0.3333\n",
            "Epoch 181/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -3172.8672 - accuracy: 0.3438 - val_loss: -3342.6492 - val_accuracy: 0.3333\n",
            "Epoch 182/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3223.2285 - accuracy: 0.3438 - val_loss: -3397.3525 - val_accuracy: 0.3333\n",
            "Epoch 183/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3276.8206 - accuracy: 0.3438 - val_loss: -3452.0442 - val_accuracy: 0.3333\n",
            "Epoch 184/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -3329.7375 - accuracy: 0.3438 - val_loss: -3507.2224 - val_accuracy: 0.3333\n",
            "Epoch 185/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3383.0598 - accuracy: 0.3438 - val_loss: -3562.9519 - val_accuracy: 0.3333\n",
            "Epoch 186/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3433.0442 - accuracy: 0.3438 - val_loss: -3620.6013 - val_accuracy: 0.3333\n",
            "Epoch 187/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3492.0254 - accuracy: 0.3438 - val_loss: -3676.8640 - val_accuracy: 0.3333\n",
            "Epoch 188/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3546.2090 - accuracy: 0.3438 - val_loss: -3734.0808 - val_accuracy: 0.3333\n",
            "Epoch 189/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3600.6406 - accuracy: 0.3438 - val_loss: -3792.3528 - val_accuracy: 0.3333\n",
            "Epoch 190/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3655.9746 - accuracy: 0.3438 - val_loss: -3851.4563 - val_accuracy: 0.3333\n",
            "Epoch 191/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -3714.2917 - accuracy: 0.3438 - val_loss: -3910.4739 - val_accuracy: 0.3333\n",
            "Epoch 192/225\n",
            "4/4 [==============================] - 0s 12ms/step - loss: -3771.1272 - accuracy: 0.3438 - val_loss: -3970.4104 - val_accuracy: 0.3333\n",
            "Epoch 193/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3830.8914 - accuracy: 0.3438 - val_loss: -4030.3574 - val_accuracy: 0.3333\n",
            "Epoch 194/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -3885.8743 - accuracy: 0.3438 - val_loss: -4092.4099 - val_accuracy: 0.3333\n",
            "Epoch 195/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -3946.8591 - accuracy: 0.3438 - val_loss: -4154.3027 - val_accuracy: 0.3333\n",
            "Epoch 196/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4004.2952 - accuracy: 0.3438 - val_loss: -4217.5923 - val_accuracy: 0.3333\n",
            "Epoch 197/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4065.1711 - accuracy: 0.3438 - val_loss: -4280.9468 - val_accuracy: 0.3333\n",
            "Epoch 198/225\n",
            "4/4 [==============================] - 0s 13ms/step - loss: -4128.1328 - accuracy: 0.3438 - val_loss: -4343.9863 - val_accuracy: 0.3333\n",
            "Epoch 199/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4187.2793 - accuracy: 0.3438 - val_loss: -4408.4658 - val_accuracy: 0.3333\n",
            "Epoch 200/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4249.2334 - accuracy: 0.3438 - val_loss: -4473.3359 - val_accuracy: 0.3333\n",
            "Epoch 201/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4311.0928 - accuracy: 0.3438 - val_loss: -4538.8882 - val_accuracy: 0.3333\n",
            "Epoch 202/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4373.8618 - accuracy: 0.3438 - val_loss: -4604.9585 - val_accuracy: 0.3333\n",
            "Epoch 203/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4438.0957 - accuracy: 0.3438 - val_loss: -4671.3618 - val_accuracy: 0.3333\n",
            "Epoch 204/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4501.8330 - accuracy: 0.3438 - val_loss: -4738.5142 - val_accuracy: 0.3333\n",
            "Epoch 205/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4565.0322 - accuracy: 0.3438 - val_loss: -4806.6489 - val_accuracy: 0.3333\n",
            "Epoch 206/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4633.9683 - accuracy: 0.3438 - val_loss: -4873.6655 - val_accuracy: 0.3333\n",
            "Epoch 207/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4698.3848 - accuracy: 0.3438 - val_loss: -4941.8013 - val_accuracy: 0.3333\n",
            "Epoch 208/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4762.6187 - accuracy: 0.3438 - val_loss: -5011.4565 - val_accuracy: 0.3333\n",
            "Epoch 209/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4830.4604 - accuracy: 0.3438 - val_loss: -5081.3716 - val_accuracy: 0.3333\n",
            "Epoch 210/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -4899.0190 - accuracy: 0.3438 - val_loss: -5151.6353 - val_accuracy: 0.3333\n",
            "Epoch 211/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -4964.7202 - accuracy: 0.3438 - val_loss: -5223.5366 - val_accuracy: 0.3333\n",
            "Epoch 212/225\n",
            "4/4 [==============================] - 0s 17ms/step - loss: -5033.4468 - accuracy: 0.3438 - val_loss: -5295.8301 - val_accuracy: 0.3333\n",
            "Epoch 213/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5101.4722 - accuracy: 0.3438 - val_loss: -5368.8330 - val_accuracy: 0.3333\n",
            "Epoch 214/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5173.0752 - accuracy: 0.3438 - val_loss: -5441.4570 - val_accuracy: 0.3333\n",
            "Epoch 215/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5243.9546 - accuracy: 0.3438 - val_loss: -5514.4062 - val_accuracy: 0.3333\n",
            "Epoch 216/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5313.9229 - accuracy: 0.3438 - val_loss: -5588.2949 - val_accuracy: 0.3333\n",
            "Epoch 217/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5384.7866 - accuracy: 0.3438 - val_loss: -5662.9395 - val_accuracy: 0.3333\n",
            "Epoch 218/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -5457.5371 - accuracy: 0.3438 - val_loss: -5737.9077 - val_accuracy: 0.3333\n",
            "Epoch 219/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -5528.3530 - accuracy: 0.3438 - val_loss: -5814.3716 - val_accuracy: 0.3333\n",
            "Epoch 220/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5603.2446 - accuracy: 0.3438 - val_loss: -5890.9277 - val_accuracy: 0.3333\n",
            "Epoch 221/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5674.2637 - accuracy: 0.3438 - val_loss: -5969.1890 - val_accuracy: 0.3333\n",
            "Epoch 222/225\n",
            "4/4 [==============================] - 0s 13ms/step - loss: -5750.7671 - accuracy: 0.3438 - val_loss: -6047.0698 - val_accuracy: 0.3333\n",
            "Epoch 223/225\n",
            "4/4 [==============================] - 0s 9ms/step - loss: -5827.2290 - accuracy: 0.3438 - val_loss: -6125.1406 - val_accuracy: 0.3333\n",
            "Epoch 224/225\n",
            "4/4 [==============================] - 0s 11ms/step - loss: -5901.7305 - accuracy: 0.3438 - val_loss: -6204.6226 - val_accuracy: 0.3333\n",
            "Epoch 225/225\n",
            "4/4 [==============================] - 0s 10ms/step - loss: -5978.0962 - accuracy: 0.3438 - val_loss: -6284.8853 - val_accuracy: 0.3333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fe17972d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = model.predict(X_test)\n",
        "y_new = [0 if val < 0.5 else 1 for val in y_new]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTUcqP6KI0vr",
        "outputId": "ddbf2a3b-3da7-41b0-859b-b34b9984fcfa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 86ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_new))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjHbNALNJsCv",
        "outputId": "bab49999-6067-43f2-c016-da26ddb3cae2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.30      1.00      0.46         9\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.30        30\n",
            "   macro avg       0.10      0.33      0.15        30\n",
            "weighted avg       0.09      0.30      0.14        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "djbBGC28Knlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data yang dibaca adalah data wine,\n",
        "# data ini belum memiliki nama variabel setiap kolom sehingga nama variabel baru ini dibuat melalui names\n",
        "\n",
        "wine = pd.read_csv('wine.csv',names = [\"Cultivator\", \"Alchol\", \"Malic_Acid\", \"Ash\", \"Alcalinity_of_Ash\", \"Magnesium\", \"Total_phenols\", \"Falvanoids\", \"Nonflavanoid_phenols\", \"Proanthocyanins\", \"Color_intensity\", \"Hue\", \"OD280\", \"Proline\"])\n",
        "\n",
        "wine.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Z4ddyK9uKHXw",
        "outputId": "3d0a976f-633d-4e39-f05f-080d24185dff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cultivator  Alchol  Malic_Acid   Ash  Alcalinity_of_Ash  Magnesium  \\\n",
              "0           1   14.23        1.71  2.43               15.6        127   \n",
              "1           1   13.20        1.78  2.14               11.2        100   \n",
              "2           1   13.16        2.36  2.67               18.6        101   \n",
              "3           1   14.37        1.95  2.50               16.8        113   \n",
              "4           1   13.24        2.59  2.87               21.0        118   \n",
              "\n",
              "   Total_phenols  Falvanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
              "0           2.80        3.06                  0.28             2.29   \n",
              "1           2.65        2.76                  0.26             1.28   \n",
              "2           2.80        3.24                  0.30             2.81   \n",
              "3           3.85        3.49                  0.24             2.18   \n",
              "4           2.80        2.69                  0.39             1.82   \n",
              "\n",
              "   Color_intensity   Hue  OD280  Proline  \n",
              "0             5.64  1.04   3.92     1065  \n",
              "1             4.38  1.05   3.40     1050  \n",
              "2             5.68  1.03   3.17     1185  \n",
              "3             7.80  0.86   3.45     1480  \n",
              "4             4.32  1.04   2.93      735  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2560208e-6f1f-4425-af56-4652432f9c40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cultivator</th>\n",
              "      <th>Alchol</th>\n",
              "      <th>Malic_Acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity_of_Ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total_phenols</th>\n",
              "      <th>Falvanoids</th>\n",
              "      <th>Nonflavanoid_phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color_intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2560208e-6f1f-4425-af56-4652432f9c40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2560208e-6f1f-4425-af56-4652432f9c40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2560208e-6f1f-4425-af56-4652432f9c40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deskripsi data dengan bentuk tampilan dibalik dari umumnya\n",
        "wine.describe().transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "65ZjJebyNJbM",
        "outputId": "9045a95e-2375-4559-99c7-16549c712c25"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      count        mean         std     min       25%  \\\n",
              "Cultivator            178.0    1.938202    0.775035    1.00    1.0000   \n",
              "Alchol                178.0   13.000618    0.811827   11.03   12.3625   \n",
              "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
              "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
              "Alcalinity_of_Ash     178.0   19.494944    3.339564   10.60   17.2000   \n",
              "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
              "Total_phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
              "Falvanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
              "Nonflavanoid_phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
              "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
              "Color_intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
              "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
              "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
              "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
              "\n",
              "                          50%       75%      max  \n",
              "Cultivator              2.000    3.0000     3.00  \n",
              "Alchol                 13.050   13.6775    14.83  \n",
              "Malic_Acid              1.865    3.0825     5.80  \n",
              "Ash                     2.360    2.5575     3.23  \n",
              "Alcalinity_of_Ash      19.500   21.5000    30.00  \n",
              "Magnesium              98.000  107.0000   162.00  \n",
              "Total_phenols           2.355    2.8000     3.88  \n",
              "Falvanoids              2.135    2.8750     5.08  \n",
              "Nonflavanoid_phenols    0.340    0.4375     0.66  \n",
              "Proanthocyanins         1.555    1.9500     3.58  \n",
              "Color_intensity         4.690    6.2000    13.00  \n",
              "Hue                     0.965    1.1200     1.71  \n",
              "OD280                   2.780    3.1700     4.00  \n",
              "Proline               673.500  985.0000  1680.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34800dac-a732-4e7d-a200-60e0e4ecafdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cultivator</th>\n",
              "      <td>178.0</td>\n",
              "      <td>1.938202</td>\n",
              "      <td>0.775035</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alchol</th>\n",
              "      <td>178.0</td>\n",
              "      <td>13.000618</td>\n",
              "      <td>0.811827</td>\n",
              "      <td>11.03</td>\n",
              "      <td>12.3625</td>\n",
              "      <td>13.050</td>\n",
              "      <td>13.6775</td>\n",
              "      <td>14.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Malic_Acid</th>\n",
              "      <td>178.0</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1.6025</td>\n",
              "      <td>1.865</td>\n",
              "      <td>3.0825</td>\n",
              "      <td>5.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ash</th>\n",
              "      <td>178.0</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>1.36</td>\n",
              "      <td>2.2100</td>\n",
              "      <td>2.360</td>\n",
              "      <td>2.5575</td>\n",
              "      <td>3.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alcalinity_of_Ash</th>\n",
              "      <td>178.0</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>10.60</td>\n",
              "      <td>17.2000</td>\n",
              "      <td>19.500</td>\n",
              "      <td>21.5000</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Magnesium</th>\n",
              "      <td>178.0</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>70.00</td>\n",
              "      <td>88.0000</td>\n",
              "      <td>98.000</td>\n",
              "      <td>107.0000</td>\n",
              "      <td>162.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_phenols</th>\n",
              "      <td>178.0</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.7425</td>\n",
              "      <td>2.355</td>\n",
              "      <td>2.8000</td>\n",
              "      <td>3.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Falvanoids</th>\n",
              "      <td>178.0</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.2050</td>\n",
              "      <td>2.135</td>\n",
              "      <td>2.8750</td>\n",
              "      <td>5.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nonflavanoid_phenols</th>\n",
              "      <td>178.0</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.2700</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <td>178.0</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.2500</td>\n",
              "      <td>1.555</td>\n",
              "      <td>1.9500</td>\n",
              "      <td>3.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Color_intensity</th>\n",
              "      <td>178.0</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>1.28</td>\n",
              "      <td>3.2200</td>\n",
              "      <td>4.690</td>\n",
              "      <td>6.2000</td>\n",
              "      <td>13.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hue</th>\n",
              "      <td>178.0</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.7825</td>\n",
              "      <td>0.965</td>\n",
              "      <td>1.1200</td>\n",
              "      <td>1.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OD280</th>\n",
              "      <td>178.0</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>1.27</td>\n",
              "      <td>1.9375</td>\n",
              "      <td>2.780</td>\n",
              "      <td>3.1700</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Proline</th>\n",
              "      <td>178.0</td>\n",
              "      <td>746.893258</td>\n",
              "      <td>314.907474</td>\n",
              "      <td>278.00</td>\n",
              "      <td>500.5000</td>\n",
              "      <td>673.500</td>\n",
              "      <td>985.0000</td>\n",
              "      <td>1680.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34800dac-a732-4e7d-a200-60e0e4ecafdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34800dac-a732-4e7d-a200-60e0e4ecafdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34800dac-a732-4e7d-a200-60e0e4ecafdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = wine.iloc[:, 1:]\n",
        "y2 = wine.iloc[:,0]"
      ],
      "metadata": {
        "id": "ziOg9UpZNTKV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data training dan testing\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2)"
      ],
      "metadata": {
        "id": "FT2Aeo09NtGH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat 'Perceptron' menggunakan Keras API\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(units=18, activation='relu', input_dim=len(X_train2.columns)))\n",
        "model2.add(Dense(units=52, activation='relu'))\n",
        "model2.add(Dense(units=1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tIeLdv-AN2fd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perceptron menggunakan penurunan gradien stokastik dengan pembagian validasi 20%\n",
        "model2.fit(X_train2, y_train2, epochs=144, batch_size=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEt4waqnOGlf",
        "outputId": "12bf98f9-96d9-4736-ff25-3108a7fa3829"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/144\n",
            "12/12 [==============================] - 1s 3ms/step - loss: -28.3984 - accuracy: 0.2632\n",
            "Epoch 2/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -136.6593 - accuracy: 0.3233\n",
            "Epoch 3/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -234.2135 - accuracy: 0.3233\n",
            "Epoch 4/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -344.9846 - accuracy: 0.3233\n",
            "Epoch 5/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -468.9449 - accuracy: 0.3233\n",
            "Epoch 6/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -632.0390 - accuracy: 0.3233\n",
            "Epoch 7/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -821.3539 - accuracy: 0.3233\n",
            "Epoch 8/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1050.2079 - accuracy: 0.3233\n",
            "Epoch 9/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1328.8951 - accuracy: 0.3233\n",
            "Epoch 10/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1651.5352 - accuracy: 0.3233\n",
            "Epoch 11/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2035.3328 - accuracy: 0.3233\n",
            "Epoch 12/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2529.8896 - accuracy: 0.3233\n",
            "Epoch 13/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3069.9446 - accuracy: 0.3233\n",
            "Epoch 14/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -3718.4041 - accuracy: 0.3233\n",
            "Epoch 15/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -4540.2285 - accuracy: 0.3233\n",
            "Epoch 16/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -5443.2236 - accuracy: 0.3233\n",
            "Epoch 17/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -6487.0068 - accuracy: 0.3233\n",
            "Epoch 18/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -7662.0376 - accuracy: 0.3233\n",
            "Epoch 19/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -9043.9824 - accuracy: 0.3233\n",
            "Epoch 20/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -10593.1484 - accuracy: 0.3233\n",
            "Epoch 21/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -12333.8223 - accuracy: 0.3233\n",
            "Epoch 22/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -14308.4414 - accuracy: 0.3233\n",
            "Epoch 23/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -16300.0547 - accuracy: 0.3233\n",
            "Epoch 24/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -18588.4746 - accuracy: 0.3233\n",
            "Epoch 25/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -21087.5488 - accuracy: 0.3233\n",
            "Epoch 26/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -23761.6758 - accuracy: 0.3233\n",
            "Epoch 27/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -26648.9707 - accuracy: 0.3233\n",
            "Epoch 28/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -29905.4102 - accuracy: 0.3233\n",
            "Epoch 29/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -33263.6211 - accuracy: 0.3233\n",
            "Epoch 30/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -37187.6797 - accuracy: 0.3233\n",
            "Epoch 31/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -41434.7305 - accuracy: 0.3233\n",
            "Epoch 32/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -45835.3242 - accuracy: 0.3233\n",
            "Epoch 33/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -50499.1797 - accuracy: 0.3233\n",
            "Epoch 34/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -55202.1914 - accuracy: 0.3233\n",
            "Epoch 35/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -60266.3320 - accuracy: 0.3233\n",
            "Epoch 36/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -65354.4141 - accuracy: 0.3233\n",
            "Epoch 37/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -70864.6250 - accuracy: 0.3233\n",
            "Epoch 38/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -76743.4141 - accuracy: 0.3233\n",
            "Epoch 39/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -82991.6484 - accuracy: 0.3233\n",
            "Epoch 40/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -89350.3594 - accuracy: 0.3233\n",
            "Epoch 41/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -96398.9766 - accuracy: 0.3233\n",
            "Epoch 42/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -103303.8281 - accuracy: 0.3233\n",
            "Epoch 43/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -111234.8906 - accuracy: 0.3233\n",
            "Epoch 44/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -119511.9219 - accuracy: 0.3233\n",
            "Epoch 45/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -128463.2031 - accuracy: 0.3233\n",
            "Epoch 46/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -137672.6719 - accuracy: 0.3233\n",
            "Epoch 47/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -146579.2500 - accuracy: 0.3233\n",
            "Epoch 48/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -156451.3438 - accuracy: 0.3233\n",
            "Epoch 49/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -166652.0000 - accuracy: 0.3233\n",
            "Epoch 50/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -177226.9844 - accuracy: 0.3233\n",
            "Epoch 51/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -187627.5781 - accuracy: 0.3233\n",
            "Epoch 52/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -198888.5781 - accuracy: 0.3233\n",
            "Epoch 53/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -210599.9844 - accuracy: 0.3233\n",
            "Epoch 54/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -222962.5625 - accuracy: 0.3233\n",
            "Epoch 55/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -236432.4531 - accuracy: 0.3233\n",
            "Epoch 56/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -249607.7031 - accuracy: 0.3233\n",
            "Epoch 57/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -262478.3750 - accuracy: 0.3233\n",
            "Epoch 58/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -276638.7188 - accuracy: 0.3233\n",
            "Epoch 59/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -291262.6250 - accuracy: 0.3233\n",
            "Epoch 60/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -306466.2812 - accuracy: 0.3233\n",
            "Epoch 61/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -321030.7188 - accuracy: 0.3233\n",
            "Epoch 62/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -337349.5625 - accuracy: 0.3233\n",
            "Epoch 63/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -354394.1250 - accuracy: 0.3233\n",
            "Epoch 64/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -370975.6562 - accuracy: 0.3233\n",
            "Epoch 65/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -389561.3438 - accuracy: 0.3233\n",
            "Epoch 66/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -407099.7812 - accuracy: 0.3233\n",
            "Epoch 67/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -425188.1250 - accuracy: 0.3233\n",
            "Epoch 68/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -444719.1562 - accuracy: 0.3233\n",
            "Epoch 69/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -465605.5625 - accuracy: 0.3233\n",
            "Epoch 70/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -484970.5000 - accuracy: 0.3233\n",
            "Epoch 71/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -505331.1250 - accuracy: 0.3233\n",
            "Epoch 72/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -525828.1875 - accuracy: 0.3233\n",
            "Epoch 73/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -547500.8750 - accuracy: 0.3233\n",
            "Epoch 74/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -569461.7500 - accuracy: 0.3233\n",
            "Epoch 75/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -593321.5625 - accuracy: 0.3233\n",
            "Epoch 76/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -615970.8750 - accuracy: 0.3233\n",
            "Epoch 77/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -638409.3125 - accuracy: 0.3233\n",
            "Epoch 78/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -661849.6875 - accuracy: 0.3233\n",
            "Epoch 79/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -684654.5000 - accuracy: 0.3233\n",
            "Epoch 80/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -710261.1250 - accuracy: 0.3233\n",
            "Epoch 81/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -735237.4375 - accuracy: 0.3233\n",
            "Epoch 82/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -761945.3125 - accuracy: 0.3233\n",
            "Epoch 83/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -791348.7500 - accuracy: 0.3233\n",
            "Epoch 84/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -820417.1875 - accuracy: 0.3233\n",
            "Epoch 85/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -849841.1875 - accuracy: 0.3233\n",
            "Epoch 86/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -878656.8750 - accuracy: 0.3233\n",
            "Epoch 87/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -907144.5000 - accuracy: 0.3233\n",
            "Epoch 88/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -935986.9375 - accuracy: 0.3233\n",
            "Epoch 89/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -967479.0000 - accuracy: 0.3233\n",
            "Epoch 90/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -998402.1875 - accuracy: 0.3233\n",
            "Epoch 91/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1029720.6875 - accuracy: 0.3233\n",
            "Epoch 92/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1061763.1250 - accuracy: 0.3233\n",
            "Epoch 93/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -1093808.2500 - accuracy: 0.3233\n",
            "Epoch 94/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -1126310.6250 - accuracy: 0.3233\n",
            "Epoch 95/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1159256.3750 - accuracy: 0.3233\n",
            "Epoch 96/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1195565.5000 - accuracy: 0.3233\n",
            "Epoch 97/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1232872.7500 - accuracy: 0.3233\n",
            "Epoch 98/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1269303.7500 - accuracy: 0.3233\n",
            "Epoch 99/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1304946.7500 - accuracy: 0.3233\n",
            "Epoch 100/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -1340643.1250 - accuracy: 0.3233\n",
            "Epoch 101/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1380058.3750 - accuracy: 0.3233\n",
            "Epoch 102/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1417925.5000 - accuracy: 0.3233\n",
            "Epoch 103/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1454881.2500 - accuracy: 0.3233\n",
            "Epoch 104/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1493802.5000 - accuracy: 0.3233\n",
            "Epoch 105/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1533942.8750 - accuracy: 0.3233\n",
            "Epoch 106/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1575505.0000 - accuracy: 0.3233\n",
            "Epoch 107/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1619395.2500 - accuracy: 0.3233\n",
            "Epoch 108/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1660861.2500 - accuracy: 0.3233\n",
            "Epoch 109/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1702285.5000 - accuracy: 0.3233\n",
            "Epoch 110/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1746936.5000 - accuracy: 0.3233\n",
            "Epoch 111/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1789707.2500 - accuracy: 0.3233\n",
            "Epoch 112/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1830325.2500 - accuracy: 0.3233\n",
            "Epoch 113/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1876471.7500 - accuracy: 0.3233\n",
            "Epoch 114/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1921521.3750 - accuracy: 0.3233\n",
            "Epoch 115/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -1972315.3750 - accuracy: 0.3233\n",
            "Epoch 116/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2020594.0000 - accuracy: 0.3233\n",
            "Epoch 117/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2069906.7500 - accuracy: 0.3233\n",
            "Epoch 118/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2121058.2500 - accuracy: 0.3233\n",
            "Epoch 119/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -2170882.2500 - accuracy: 0.3233\n",
            "Epoch 120/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -2219672.0000 - accuracy: 0.3233\n",
            "Epoch 121/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2270409.5000 - accuracy: 0.3233\n",
            "Epoch 122/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2322997.5000 - accuracy: 0.3233\n",
            "Epoch 123/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2372942.7500 - accuracy: 0.3233\n",
            "Epoch 124/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2424004.2500 - accuracy: 0.3233\n",
            "Epoch 125/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2476371.7500 - accuracy: 0.3233\n",
            "Epoch 126/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2531904.7500 - accuracy: 0.3233\n",
            "Epoch 127/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2583464.5000 - accuracy: 0.3233\n",
            "Epoch 128/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -2644317.5000 - accuracy: 0.3233\n",
            "Epoch 129/144\n",
            "12/12 [==============================] - 0s 3ms/step - loss: -2702024.7500 - accuracy: 0.3233\n",
            "Epoch 130/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2760347.2500 - accuracy: 0.3233\n",
            "Epoch 131/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2822401.7500 - accuracy: 0.3233\n",
            "Epoch 132/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2883056.7500 - accuracy: 0.3233\n",
            "Epoch 133/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -2943491.7500 - accuracy: 0.3233\n",
            "Epoch 134/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3010255.0000 - accuracy: 0.3233\n",
            "Epoch 135/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3078769.0000 - accuracy: 0.3233\n",
            "Epoch 136/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3142347.5000 - accuracy: 0.3233\n",
            "Epoch 137/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3212039.5000 - accuracy: 0.3233\n",
            "Epoch 138/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3282442.7500 - accuracy: 0.3233\n",
            "Epoch 139/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3346865.2500 - accuracy: 0.3233\n",
            "Epoch 140/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3411217.2500 - accuracy: 0.3233\n",
            "Epoch 141/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3477123.2500 - accuracy: 0.3233\n",
            "Epoch 142/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3540675.2500 - accuracy: 0.3233\n",
            "Epoch 143/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3607268.5000 - accuracy: 0.3233\n",
            "Epoch 144/144\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -3676110.7500 - accuracy: 0.3233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fe22b80d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new2 = model2.predict(X_test2)\n",
        "y_new2 = [0 if val < 0.5 else 1 for val in y_new2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T5lo0QNOX9Z",
        "outputId": "917b275b-1076-490e-ef99-9d8bf724facd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_new2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZNQRcprOyVe",
        "outputId": "db25300c-b127-4462-f604-d1b9d5ba6567"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.36      1.00      0.52        16\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.36        45\n",
            "   macro avg       0.12      0.33      0.17        45\n",
            "weighted avg       0.13      0.36      0.19        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwr13VlMRals"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}